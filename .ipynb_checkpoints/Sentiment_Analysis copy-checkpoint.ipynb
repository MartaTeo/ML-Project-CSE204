{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "889221e1-f7b9-489f-b815-12e537f0491a",
   "metadata": {},
   "source": [
    "# This notebook will show the implementation of NLP upon text reviews in our database of Amazon reviews. \n",
    "\n",
    "## We will explain each step and their results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf317bf-aa79-4734-af43-104ebba57fd2",
   "metadata": {},
   "source": [
    "We import some of the main libraries we will work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e2b5d-1e61-477a-907e-143c05ea6560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6ea21-d382-4115-89b6-adf203eebdc2",
   "metadata": {},
   "source": [
    "Now, let us upload the database and observe it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba620d-1e1a-4dc4-845e-ffed5ed0b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_reviews = pd.read_csv(\"Amazon Reviews 1.csv\")\n",
    "#amazon_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df81fd-6ed5-4bf7-843f-203c528edc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8c93b7-cec7-4cd2-ae64-25d5145ef881",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_reviews.dropna(subset = [\"reviews.text\"])\n",
    "amazon_reviews.dropna(subset = [\"reviews.title\"])\n",
    "amazon_reviews.dropna(subset = [\"reviews.rating\"])\n",
    "\n",
    "amazon_reviews.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b44770-0112-4178-8bc7-45c87d281d2a",
   "metadata": {},
   "source": [
    "## The data is unevenly distributed along the ratings, we will solve this issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b245b-242e-451d-9da8-b20882e6f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_select(df, n, rating, column): #choose the database and the number of samples with the indicated rating (specify the \n",
    "                                            # name of the column)\n",
    "    rating_df = df[df[column] == rating]\n",
    "    dff = rating_df.sample(n=n, random_state=42) \n",
    "\n",
    "    return dff\n",
    "\n",
    "df3 = random_select(amazon_reviews, 400, 3, 'reviews.rating')\n",
    "df4 = random_select(amazon_reviews, 350, 4, 'reviews.rating')\n",
    "df5 = random_select(amazon_reviews, 1000, 5, 'reviews.rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d7632-efc3-4f36-8538-60093c6f1693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170d7d9-f006-4590-861f-5db80d0d164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c86f3c-b469-4252-be26-731d7778f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a0d2ca-2293-4d06-a99e-3f220b418151",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12 = amazon_reviews[amazon_reviews['reviews.rating'].isin([1, 2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9606dd6-dfb1-4552-8980-47413988883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6364fb-786b-4adf-91d3-57acbe5e4292",
   "metadata": {},
   "source": [
    "Now, we observe that the columns we will work with are id (or name, they are correlated) and reviews.text. We will create a new database with these two and add a column based on the reviews.rating :\n",
    "\n",
    "- 5 : good (2)\n",
    "- 3, 4 : neutral (1)\n",
    "- 1, 2 : bad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b9296-51d9-411c-8b9f-1d15f1c77765",
   "metadata": {},
   "source": [
    "### Now let us create the final database we will actually work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589c95e-6497-4ecf-975b-8ea22441ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = pd.concat([df12, df3, df4, df5], ignore_index=True)\n",
    "amazon.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373c8fe2-a3c8-4482-9925-f65ed69046e7",
   "metadata": {},
   "source": [
    "## We now need to create the label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cec782-4b0b-4c57-a085-723abfcd9e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label(r):\n",
    "    if r == 5.0:\n",
    "        return 2\n",
    "    elif r == 3.0 or r == 4.0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "amazon['label'] = amazon['reviews.rating'].apply(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f3de4-6f02-4f20-a498-9299c0ee7ece",
   "metadata": {},
   "source": [
    "# This will be the database for our Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b0d811-ed5e-4fed-9d9d-e516fd7685b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = amazon[['id', 'reviews.text', 'reviews.rating', 'label']]\n",
    "amazon.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4bec79-a2ff-4c82-948b-8aced86d0329",
   "metadata": {},
   "source": [
    "## Let us observe how our database behaves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f765e21-ca8b-4e9d-b67d-b8dc47e6504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = amazon['label']\n",
    "min_bin = - 0.5\n",
    "max_bin = 2.5\n",
    "bins = np.arange(min_bin, max_bin + 1, 1)  \n",
    "\n",
    "counts, edges = np.histogram(data, bins=bins)\n",
    "\n",
    "bar_width = 0.75\n",
    "\n",
    "for left, height in zip(edges[:-1], counts):\n",
    "    plt.bar(left + 0.5 * (1 - bar_width), height, width=bar_width, align='edge', color='#9b00d9')\n",
    "\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram with spacing between bars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e4b171-4e96-48b7-a5d8-3f6bdcd50d09",
   "metadata": {},
   "source": [
    "## Now, let us part our database in the three categories we have defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e60be6-326a-4af0-84f1-ccf54a884760",
   "metadata": {},
   "outputs": [],
   "source": [
    "good = amazon[amazon['label'] == 2]\n",
    "neutral = amazon[amazon['label'] == 1]\n",
    "bad = amazon[amazon['label'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a72d7f7-cb71-4d34-a359-a12feebdec3e",
   "metadata": {},
   "source": [
    "### In order to better visualise these, we can plot some wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f8c0e3-4d67-4f1b-b785-6ed275f6a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf5667-e5d1-4dfc-bb73-4429725b546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "goods = good['reviews.text'].tolist()\n",
    "goods = [str(x) for x in goods]\n",
    "goods_sentence = \" \".join(goods)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(WordCloud().generate(goods_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40676a27-56f0-4c81-a093-5fa7d98a4048",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutrals = neutral['reviews.text'].tolist()\n",
    "neutrals = [str(x) for x in neutrals]\n",
    "neutrals_sentence = \" \".join(neutrals)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(WordCloud().generate(neutrals_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9839068-6e6e-47ff-bdba-cc72a3be710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bads = bad['reviews.text'].tolist()\n",
    "bads = [str(x) for x in bads]\n",
    "bads_sentence = \" \".join(bads)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(WordCloud().generate(bads_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53361607-3efd-496b-9b12-e96a87128687",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37d5294-be0c-433c-ab7f-7d1f8ea6a373",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dc03b5-873a-4ae2-b12b-ec6ec3fa7d12",
   "metadata": {},
   "source": [
    "# Now it's time for some data cleaning!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8511f62f-48a6-42cd-880e-7f3948d05afd",
   "metadata": {},
   "source": [
    "## Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be744a83-5115-4180-bbd2-83accaf401e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9904f311-8e00-41b5-9214-f894b41b0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For good\n",
    "g = []\n",
    "for s in goods:\n",
    "    sentence = [c for c in s if c not in string.punctuation]\n",
    "    s = ''.join(sentence)\n",
    "    g.append(s)\n",
    "goods = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510fef93-8a6c-40bd-b5f6-5547b2989ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For neutral\n",
    "n = []\n",
    "for s in neutrals:\n",
    "    sentence = [c for c in s if c not in string.punctuation]\n",
    "    s = ''.join(sentence)\n",
    "    n.append(s)\n",
    "neutrals = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998b7a1a-b69a-4e82-bd29-7a4243cae39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For bad\n",
    "b = []\n",
    "for s in bads:\n",
    "    sentence = [c for c in s if c not in string.punctuation]\n",
    "    s = ''.join(sentence)\n",
    "    b.append(s)\n",
    "bads = b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa889c19-d714-4bc1-a735-4e7f0f133f65",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d099b818-b491-423e-b53d-1ea113af2747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8314079d-0c85-4eae-b3d5-885548657e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For good\n",
    "\"\"\"\n",
    "g = []\n",
    "for s in goods:\n",
    "    sentence = [word for word in s.split() if word not in stopwords.words('english')]\n",
    "    s = ' '.join(sentence)\n",
    "    g.append(s)\n",
    "\n",
    "goods = g\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6421b10-ce91-402d-bb46-a6546e3bbdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For neutral\n",
    "\"\"\"\n",
    "n = []\n",
    "for s in neutrals:\n",
    "    sentence = [word for word in s.split() if word not in stopwords.words('english')]\n",
    "    s = ' '.join(sentence)\n",
    "    g=n.append(s)\n",
    "\n",
    "neutrals = n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8d4a9-d8fc-43f7-8414-f59526ab86a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For bad\n",
    "\"\"\"\n",
    "b = []\n",
    "for s in bads:\n",
    "    sentence = [word for word in s.split() if word not in stopwords.words('english')]\n",
    "    s = ' '.join(sentence)\n",
    "    b.append(s)\n",
    "\n",
    "bads = b\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d787555f-0f4a-4b47-a953-144e6541e95f",
   "metadata": {},
   "source": [
    "## Now, let us put it all together into a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bad08e-041b-4b32-b74a-e59232ba4975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(text):\n",
    "\n",
    "    Test_punc_removed = [char for char in text if char not in string.punctuation]\n",
    "    Test_punc_removed_join = ''.join(Test_punc_removed)\n",
    "    Test_punc_removed_join_clean = [word for word in Test_punc_removed_join.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    return Test_punc_removed_join_clean    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996657d-5902-4862-b9cd-466ba0470ace",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea8a4c-a256-4e9a-abbe-5a9b4779788d",
   "metadata": {},
   "source": [
    "# Now we can perform tokenization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44711e-7de0-4cc1-bbd0-bef55458ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54100f2a-de8f-40de-9a5e-888651e2f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amazon_clean = amazon['reviews.text'].apply(data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5dab04-ad49-4374-8e1d-5fde5fca0b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(amazon_clean[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbb16ef-73ca-4ab3-81f6-191f2176f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f357da85-0752-4aeb-8ada-ff5c1e117c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = data_cleaning, dtype = np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895510e4-7dfd-402e-8450-229cb2a3d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_countvectorizer = vectorizer.fit_transform(amazon['reviews.text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3fa90-aba5-4805-8a66-3f849156bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(amazon_countvectorizer.toarray())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fbc81c-3730-4ba2-8f43-d5898622b8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_countvectorizer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97363eb-894d-4a1d-ba04-4de2bf080ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(amazon_countvectorizer.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683d013c-1889-42b1-9f0d-7939a8f00da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb1199-1db1-4920-9675-a2b4a0795526",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8e156b-0f66-4a0f-b9db-f3b88a09b3b2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46044af2-abf9-47b9-9cef-e2b4e5c8f10c",
   "metadata": {},
   "source": [
    "# We will now use Naive Bayes in order to continue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ee782-58dd-441b-a6e5-8a949c6e61a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = amazon['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dfd71d-659a-4e4e-839c-f13865825d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa167a29-201c-4447-a6f5-760dfa1336ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e0715a-2cdb-4969-8486-23df58fb8472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e45d75-18be-4fe7-99e2-93b6ebcf4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB_classifier = MultinomialNB()\n",
    "NB_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46749e3-ca96-435e-83a0-24c594ea4339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186ecbf2-29f2-4dad-ad1f-9fe56023fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_predict_test = NB_classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict_test)\n",
    "sns.heatmap(cm, annot=True, cmap=\"PiYG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a6c67-013b-4cc8-a24b-8d65c1dbe82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb9cd37-0888-4ea7-8405-643156d2deec",
   "metadata": {},
   "source": [
    "# More Methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f8bcc-cbca-4a87-b228-9df44953baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_test)\n",
    "sns.heatmap(cm, annot = True, cmap=\"coolwarm\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8fd104-74d0-407a-afb5-b8fecb2d1642",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2700cb4c-2df4-4024-aa2d-775442c2a51f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77167bd7-57b3-4fc6-8982-de168331045a",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57abf202-ad52-4edf-a158-08bab17b73e1",
   "metadata": {},
   "source": [
    "# At this point we can observe that the accuracy is worryingly low, how the model works best on extremes, but has really big troubles in detecting the neutral labels. We will therefore train on the whole database for the sake of it and look for a better accuracy - at least for the extreme labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cda408-aca1-4636-a915-c41580548831",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_reviews = pd.read_csv(\"Amazon Reviews 1.csv\")\n",
    "amazon_reviews.dropna(subset = [\"reviews.text\"])\n",
    "amazon_reviews.dropna(subset = [\"reviews.title\"])\n",
    "amazon_reviews.dropna(subset = [\"reviews.rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e92fb04-a02c-4912-93e6-0bae1bd41854",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = amazon_reviews[['id', 'reviews.text', 'reviews.rating']]\n",
    "amazon.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b1fd3b-011d-4203-a255-6d84d85fa92f",
   "metadata": {},
   "source": [
    "## In case we have NaN entries for the reviews' text, we just \"clean\" them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dfc81b-e4be-4a9c-9435-ba435d646664",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon['reviews.text'] = amazon['reviews.text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a7999-9493-430d-9e30-9353981917ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(r):\n",
    "    if r == 5.0:\n",
    "        return 2\n",
    "    elif r == 3.0 or r == 4.0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "amazon['label'] = amazon['reviews.rating'].apply(label)\n",
    "amazon.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd71d789-7cad-4e13-96d3-2bb409016c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = amazon['label']\n",
    "min_bin = - 0.5\n",
    "max_bin = 2.5\n",
    "bins = np.arange(min_bin, max_bin + 1, 1)  \n",
    "\n",
    "counts, edges = np.histogram(data, bins=bins)\n",
    "\n",
    "bar_width = 0.75\n",
    "\n",
    "for left, height in zip(edges[:-1], counts):\n",
    "    plt.bar(left + 0.5 * (1 - bar_width), height, width=bar_width, align='edge', color='#9b00d9')\n",
    "\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram with spacing between bars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c042267-5b77-4266-82c4-d356fe4bb906",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = data_cleaning, dtype = np.uint8)\n",
    "amazon_countvectorizer = vectorizer.fit_transform(amazon['reviews.text'])\n",
    "print(amazon_countvectorizer.toarray())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ffb59-7113-43fa-938c-6f1a2105f627",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(amazon_countvectorizer.toarray())\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9072e116-4a9b-4502-b9c5-772a0981ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = amazon['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c016bb3-2ae7-4eb0-ab1d-2aeb0075e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c47ae-43c9-453b-9696-d7eb067b37dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB_classifier = MultinomialNB()\n",
    "NB_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22bf21-e8d5-41d9-9834-b675e9b3a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_predict_test = NB_classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_predict_test)\n",
    "sns.heatmap(cm, annot=True, cmap=\"PiYG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614b56f3-8e69-4ef4-bd6c-71bdd2da6c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb89408d-db41-4cac-8d24-9cc727ff3989",
   "metadata": {},
   "source": [
    "## For more methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb0d67a-328f-4a38-a3f9-f0678e627c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_pred, y_test)\n",
    "sns.heatmap(cm, annot = True, cmap=\"coolwarm\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bea78f-3d87-4dac-800c-440b6d222275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f09e00b-2a43-4d05-93d4-53ec818f9f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517d9df-3908-4fbd-bb0b-1c04ae5e931e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
